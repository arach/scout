{
  "timestamp": "2025-07-10T20:14:00.919511+00:00",
  "test_description": "Ring Buffer chunk size optimization analysis",
  "chunk_sizes_tested": [
    500,
    1000,
    2000,
    3000,
    5000
  ],
  "results": [
    {
      "test_name": "Short_recording_6",
      "recording_duration_ms": 3332,
      "recording_category": "Short",
      "chunk_size_ms": 500,
      "time_to_first_chunk_ms": 500.0,
      "time_to_50_percent_ms": 1750.0,
      "total_transcription_time_ms": 240.0,
      "chunks_processed": 7,
      "final_transcription": "Thanks, let's see how that works.  Long.  you",
      "chunk_boundary_artifacts": 6,
      "overall_quality_score": 0.83,
      "processing_queue_transcription": "Thanks, let's see how that works.  Long.  you",
      "quality_vs_processing_queue": 1.0,
      "success": true,
      "error": null
    },
    {
      "test_name": "Short_recording_5",
      "recording_duration_ms": 2914,
      "recording_category": "Short",
      "chunk_size_ms": 500,
      "time_to_first_chunk_ms": 500.0,
      "time_to_50_percent_ms": 1500.0,
      "total_transcription_time_ms": 3203.0,
      "chunks_processed": 6,
      "final_transcription": "Ah My Dear",
      "chunk_boundary_artifacts": 5,
      "overall_quality_score": 0.85,
      "processing_queue_transcription": "Ah My Dear",
      "quality_vs_processing_queue": 1.0,
      "success": true,
      "error": null
    },
    {
      "test_name": "Medium_recording_9",
      "recording_duration_ms": 6881,
      "recording_category": "Medium",
      "chunk_size_ms": 500,
      "time_to_first_chunk_ms": 500.0,
      "time_to_50_percent_ms": 3500.0,
      "total_transcription_time_ms": 179.0,
      "chunks_processed": 14,
      "final_transcription": "Okay, well our system doesn't seem to want to use profanity anymore.",
      "chunk_boundary_artifacts": 13,
      "overall_quality_score": 0.75,
      "processing_queue_transcription": "Okay, well our system doesn't seem to want to use profanity anymore.",
      "quality_vs_processing_queue": 1.0,
      "success": true,
      "error": null
    },
    {
      "test_name": "Medium_recording_8",
      "recording_duration_ms": 7673,
      "recording_category": "Medium",
      "chunk_size_ms": 500,
      "time_to_first_chunk_ms": 500.0,
      "time_to_50_percent_ms": 4000.0,
      "total_transcription_time_ms": 201.0,
      "chunks_processed": 16,
      "final_transcription": "Well, the good news is this is after build, so we were able to build cleanly, but this",
      "chunk_boundary_artifacts": 15,
      "overall_quality_score": 0.75,
      "processing_queue_transcription": "Well, the good news is this is after build, so we were able to build cleanly, but this",
      "quality_vs_processing_queue": 1.0,
      "success": true,
      "error": null
    },
    {
      "test_name": "Long_recording_12",
      "recording_duration_ms": 42553,
      "recording_category": "Long",
      "chunk_size_ms": 500,
      "time_to_first_chunk_ms": 500.0,
      "time_to_50_percent_ms": 21500.0,
      "total_transcription_time_ms": 844.0,
      "chunks_processed": 86,
      "final_transcription": "In addition to that, I'm thinking that there might be actual value in  Potentially, I'm not saying this for a fact, but potentially having progressive  improvements on transcription meaning that we could have like a quick first snap at the transcription and  Then a behind-the-scenes process of improving the transcription with a more  Sophisticated model where you would do a diff and then kind of come up with a  Determination of whether or not the diff is improving or not which probably will right  But but that's kind of something that I've been thinking about",
      "chunk_boundary_artifacts": 85,
      "overall_quality_score": 0.75,
      "processing_queue_transcription": "In addition to that, I'm thinking that there might be actual value in  Potentially, I'm not saying this for a fact, but potentially having progressive  improvements on transcription meaning that we could have like a quick first snap at the transcription and  Then a behind-the-scenes process of improving the transcription with a more  Sophisticated model where you would do a diff and then kind of come up with a  Determination of whether or not the diff is improving or not which probably will right  But but that's kind of something that I've been thinking about",
      "quality_vs_processing_queue": 1.0,
      "success": true,
      "error": null
    },
    {
      "test_name": "Short_recording_6",
      "recording_duration_ms": 3332,
      "recording_category": "Short",
      "chunk_size_ms": 1000,
      "time_to_first_chunk_ms": 1000.0,
      "time_to_50_percent_ms": 2000.0,
      "total_transcription_time_ms": 248.0,
      "chunks_processed": 4,
      "final_transcription": "Thanks, let's see how that works.  Long.  you",
      "chunk_boundary_artifacts": 3,
      "overall_quality_score": 0.8899999999999999,
      "processing_queue_transcription": "Thanks, let's see how that works.  Long.  you",
      "quality_vs_processing_queue": 1.0,
      "success": true,
      "error": null
    },
    {
      "test_name": "Short_recording_5",
      "recording_duration_ms": 2914,
      "recording_category": "Short",
      "chunk_size_ms": 1000,
      "time_to_first_chunk_ms": 1000.0,
      "time_to_50_percent_ms": 1500.0,
      "total_transcription_time_ms": 3192.0,
      "chunks_processed": 3,
      "final_transcription": "Ah My Dear",
      "chunk_boundary_artifacts": 2,
      "overall_quality_score": 0.9099999999999999,
      "processing_queue_transcription": "Ah My Dear",
      "quality_vs_processing_queue": 1.0,
      "success": true,
      "error": null
    },
    {
      "test_name": "Medium_recording_9",
      "recording_duration_ms": 6881,
      "recording_category": "Medium",
      "chunk_size_ms": 1000,
      "time_to_first_chunk_ms": 1000.0,
      "time_to_50_percent_ms": 3500.0,
      "total_transcription_time_ms": 190.0,
      "chunks_processed": 7,
      "final_transcription": "Okay, well our system doesn't seem to want to use profanity anymore.",
      "chunk_boundary_artifacts": 6,
      "overall_quality_score": 0.83,
      "processing_queue_transcription": "Okay, well our system doesn't seem to want to use profanity anymore.",
      "quality_vs_processing_queue": 1.0,
      "success": true,
      "error": null
    },
    {
      "test_name": "Medium_recording_8",
      "recording_duration_ms": 7673,
      "recording_category": "Medium",
      "chunk_size_ms": 1000,
      "time_to_first_chunk_ms": 1000.0,
      "time_to_50_percent_ms": 4000.0,
      "total_transcription_time_ms": 265.0,
      "chunks_processed": 8,
      "final_transcription": "Well, the good news is this is after build, so we were able to build cleanly, but this",
      "chunk_boundary_artifacts": 7,
      "overall_quality_score": 0.8099999999999999,
      "processing_queue_transcription": "Well, the good news is this is after build, so we were able to build cleanly, but this",
      "quality_vs_processing_queue": 1.0,
      "success": true,
      "error": null
    },
    {
      "test_name": "Long_recording_12",
      "recording_duration_ms": 42553,
      "recording_category": "Long",
      "chunk_size_ms": 1000,
      "time_to_first_chunk_ms": 1000.0,
      "time_to_50_percent_ms": 21500.0,
      "total_transcription_time_ms": 940.0,
      "chunks_processed": 43,
      "final_transcription": "In addition to that, I'm thinking that there might be actual value in  Potentially, I'm not saying this for a fact, but potentially having progressive  improvements on transcription meaning that we could have like a quick first snap at the transcription and  Then a behind-the-scenes process of improving the transcription with a more  Sophisticated model where you would do a diff and then kind of come up with a  Determination of whether or not the diff is improving or not which probably will right  But but that's kind of something that I've been thinking about",
      "chunk_boundary_artifacts": 42,
      "overall_quality_score": 0.75,
      "processing_queue_transcription": "In addition to that, I'm thinking that there might be actual value in  Potentially, I'm not saying this for a fact, but potentially having progressive  improvements on transcription meaning that we could have like a quick first snap at the transcription and  Then a behind-the-scenes process of improving the transcription with a more  Sophisticated model where you would do a diff and then kind of come up with a  Determination of whether or not the diff is improving or not which probably will right  But but that's kind of something that I've been thinking about",
      "quality_vs_processing_queue": 1.0,
      "success": true,
      "error": null
    },
    {
      "test_name": "Short_recording_6",
      "recording_duration_ms": 3332,
      "recording_category": "Short",
      "chunk_size_ms": 2000,
      "time_to_first_chunk_ms": 2000.0,
      "time_to_50_percent_ms": 2000.0,
      "total_transcription_time_ms": 252.0,
      "chunks_processed": 2,
      "final_transcription": "Thanks, let's see how that works.  Long.  you",
      "chunk_boundary_artifacts": 1,
      "overall_quality_score": 0.9299999999999999,
      "processing_queue_transcription": "Thanks, let's see how that works.  Long.  you",
      "quality_vs_processing_queue": 1.0,
      "success": true,
      "error": null
    },
    {
      "test_name": "Short_recording_5",
      "recording_duration_ms": 2914,
      "recording_category": "Short",
      "chunk_size_ms": 2000,
      "time_to_first_chunk_ms": 2000.0,
      "time_to_50_percent_ms": 2000.0,
      "total_transcription_time_ms": 3740.0,
      "chunks_processed": 2,
      "final_transcription": "Ah My Dear",
      "chunk_boundary_artifacts": 1,
      "overall_quality_score": 0.9299999999999999,
      "processing_queue_transcription": "Ah My Dear",
      "quality_vs_processing_queue": 1.0,
      "success": true,
      "error": null
    },
    {
      "test_name": "Medium_recording_9",
      "recording_duration_ms": 6881,
      "recording_category": "Medium",
      "chunk_size_ms": 2000,
      "time_to_first_chunk_ms": 2000.0,
      "time_to_50_percent_ms": 4000.0,
      "total_transcription_time_ms": 202.0,
      "chunks_processed": 4,
      "final_transcription": "Okay, well our system doesn't seem to want to use profanity anymore.",
      "chunk_boundary_artifacts": 3,
      "overall_quality_score": 0.8899999999999999,
      "processing_queue_transcription": "Okay, well our system doesn't seem to want to use profanity anymore.",
      "quality_vs_processing_queue": 1.0,
      "success": true,
      "error": null
    },
    {
      "test_name": "Medium_recording_8",
      "recording_duration_ms": 7673,
      "recording_category": "Medium",
      "chunk_size_ms": 2000,
      "time_to_first_chunk_ms": 2000.0,
      "time_to_50_percent_ms": 4000.0,
      "total_transcription_time_ms": 204.0,
      "chunks_processed": 4,
      "final_transcription": "Well, the good news is this is after build, so we were able to build cleanly, but this",
      "chunk_boundary_artifacts": 3,
      "overall_quality_score": 0.8899999999999999,
      "processing_queue_transcription": "Well, the good news is this is after build, so we were able to build cleanly, but this",
      "quality_vs_processing_queue": 1.0,
      "success": true,
      "error": null
    },
    {
      "test_name": "Long_recording_12",
      "recording_duration_ms": 42553,
      "recording_category": "Long",
      "chunk_size_ms": 2000,
      "time_to_first_chunk_ms": 2000.0,
      "time_to_50_percent_ms": 22000.0,
      "total_transcription_time_ms": 921.0,
      "chunks_processed": 22,
      "final_transcription": "In addition to that, I'm thinking that there might be actual value in  Potentially, I'm not saying this for a fact, but potentially having progressive  improvements on transcription meaning that we could have like a quick first snap at the transcription and  Then a behind-the-scenes process of improving the transcription with a more  Sophisticated model where you would do a diff and then kind of come up with a  Determination of whether or not the diff is improving or not which probably will right  But but that's kind of something that I've been thinking about",
      "chunk_boundary_artifacts": 21,
      "overall_quality_score": 0.75,
      "processing_queue_transcription": "In addition to that, I'm thinking that there might be actual value in  Potentially, I'm not saying this for a fact, but potentially having progressive  improvements on transcription meaning that we could have like a quick first snap at the transcription and  Then a behind-the-scenes process of improving the transcription with a more  Sophisticated model where you would do a diff and then kind of come up with a  Determination of whether or not the diff is improving or not which probably will right  But but that's kind of something that I've been thinking about",
      "quality_vs_processing_queue": 1.0,
      "success": true,
      "error": null
    },
    {
      "test_name": "Short_recording_6",
      "recording_duration_ms": 3332,
      "recording_category": "Short",
      "chunk_size_ms": 3000,
      "time_to_first_chunk_ms": 3000.0,
      "time_to_50_percent_ms": 3000.0,
      "total_transcription_time_ms": 270.0,
      "chunks_processed": 2,
      "final_transcription": "Thanks, let's see how that works.  Long.  you",
      "chunk_boundary_artifacts": 1,
      "overall_quality_score": 0.9299999999999999,
      "processing_queue_transcription": "Thanks, let's see how that works.  Long.  you",
      "quality_vs_processing_queue": 1.0,
      "success": true,
      "error": null
    },
    {
      "test_name": "Short_recording_5",
      "recording_duration_ms": 2914,
      "recording_category": "Short",
      "chunk_size_ms": 3000,
      "time_to_first_chunk_ms": 3000.0,
      "time_to_50_percent_ms": 1500.0,
      "total_transcription_time_ms": 3206.0,
      "chunks_processed": 1,
      "final_transcription": "Ah My Dear",
      "chunk_boundary_artifacts": 0,
      "overall_quality_score": 0.95,
      "processing_queue_transcription": "Ah My Dear",
      "quality_vs_processing_queue": 1.0,
      "success": true,
      "error": null
    },
    {
      "test_name": "Medium_recording_9",
      "recording_duration_ms": 6881,
      "recording_category": "Medium",
      "chunk_size_ms": 3000,
      "time_to_first_chunk_ms": 3000.0,
      "time_to_50_percent_ms": 4500.0,
      "total_transcription_time_ms": 179.0,
      "chunks_processed": 3,
      "final_transcription": "Okay, well our system doesn't seem to want to use profanity anymore.",
      "chunk_boundary_artifacts": 2,
      "overall_quality_score": 0.9099999999999999,
      "processing_queue_transcription": "Okay, well our system doesn't seem to want to use profanity anymore.",
      "quality_vs_processing_queue": 1.0,
      "success": true,
      "error": null
    },
    {
      "test_name": "Medium_recording_8",
      "recording_duration_ms": 7673,
      "recording_category": "Medium",
      "chunk_size_ms": 3000,
      "time_to_first_chunk_ms": 3000.0,
      "time_to_50_percent_ms": 4500.0,
      "total_transcription_time_ms": 206.0,
      "chunks_processed": 3,
      "final_transcription": "Well, the good news is this is after build, so we were able to build cleanly, but this",
      "chunk_boundary_artifacts": 2,
      "overall_quality_score": 0.9099999999999999,
      "processing_queue_transcription": "Well, the good news is this is after build, so we were able to build cleanly, but this",
      "quality_vs_processing_queue": 1.0,
      "success": true,
      "error": null
    },
    {
      "test_name": "Long_recording_12",
      "recording_duration_ms": 42553,
      "recording_category": "Long",
      "chunk_size_ms": 3000,
      "time_to_first_chunk_ms": 3000.0,
      "time_to_50_percent_ms": 22500.0,
      "total_transcription_time_ms": 840.0,
      "chunks_processed": 15,
      "final_transcription": "In addition to that, I'm thinking that there might be actual value in  Potentially, I'm not saying this for a fact, but potentially having progressive  improvements on transcription meaning that we could have like a quick first snap at the transcription and  Then a behind-the-scenes process of improving the transcription with a more  Sophisticated model where you would do a diff and then kind of come up with a  Determination of whether or not the diff is improving or not which probably will right  But but that's kind of something that I've been thinking about",
      "chunk_boundary_artifacts": 14,
      "overall_quality_score": 0.75,
      "processing_queue_transcription": "In addition to that, I'm thinking that there might be actual value in  Potentially, I'm not saying this for a fact, but potentially having progressive  improvements on transcription meaning that we could have like a quick first snap at the transcription and  Then a behind-the-scenes process of improving the transcription with a more  Sophisticated model where you would do a diff and then kind of come up with a  Determination of whether or not the diff is improving or not which probably will right  But but that's kind of something that I've been thinking about",
      "quality_vs_processing_queue": 1.0,
      "success": true,
      "error": null
    },
    {
      "test_name": "Short_recording_6",
      "recording_duration_ms": 3332,
      "recording_category": "Short",
      "chunk_size_ms": 5000,
      "time_to_first_chunk_ms": 5000.0,
      "time_to_50_percent_ms": 2500.0,
      "total_transcription_time_ms": 269.0,
      "chunks_processed": 1,
      "final_transcription": "Thanks, let's see how that works.  Long.  you",
      "chunk_boundary_artifacts": 0,
      "overall_quality_score": 0.95,
      "processing_queue_transcription": "Thanks, let's see how that works.  Long.  you",
      "quality_vs_processing_queue": 1.0,
      "success": true,
      "error": null
    },
    {
      "test_name": "Short_recording_5",
      "recording_duration_ms": 2914,
      "recording_category": "Short",
      "chunk_size_ms": 5000,
      "time_to_first_chunk_ms": 5000.0,
      "time_to_50_percent_ms": 2500.0,
      "total_transcription_time_ms": 3339.0,
      "chunks_processed": 1,
      "final_transcription": "Ah My Dear",
      "chunk_boundary_artifacts": 0,
      "overall_quality_score": 0.95,
      "processing_queue_transcription": "Ah My Dear",
      "quality_vs_processing_queue": 1.0,
      "success": true,
      "error": null
    },
    {
      "test_name": "Medium_recording_9",
      "recording_duration_ms": 6881,
      "recording_category": "Medium",
      "chunk_size_ms": 5000,
      "time_to_first_chunk_ms": 5000.0,
      "time_to_50_percent_ms": 5000.0,
      "total_transcription_time_ms": 186.0,
      "chunks_processed": 2,
      "final_transcription": "Okay, well our system doesn't seem to want to use profanity anymore.",
      "chunk_boundary_artifacts": 1,
      "overall_quality_score": 0.9299999999999999,
      "processing_queue_transcription": "Okay, well our system doesn't seem to want to use profanity anymore.",
      "quality_vs_processing_queue": 1.0,
      "success": true,
      "error": null
    },
    {
      "test_name": "Medium_recording_8",
      "recording_duration_ms": 7673,
      "recording_category": "Medium",
      "chunk_size_ms": 5000,
      "time_to_first_chunk_ms": 5000.0,
      "time_to_50_percent_ms": 5000.0,
      "total_transcription_time_ms": 213.0,
      "chunks_processed": 2,
      "final_transcription": "Well, the good news is this is after build, so we were able to build cleanly, but this",
      "chunk_boundary_artifacts": 1,
      "overall_quality_score": 0.9299999999999999,
      "processing_queue_transcription": "Well, the good news is this is after build, so we were able to build cleanly, but this",
      "quality_vs_processing_queue": 1.0,
      "success": true,
      "error": null
    },
    {
      "test_name": "Long_recording_12",
      "recording_duration_ms": 42553,
      "recording_category": "Long",
      "chunk_size_ms": 5000,
      "time_to_first_chunk_ms": 5000.0,
      "time_to_50_percent_ms": 22500.0,
      "total_transcription_time_ms": 1146.0,
      "chunks_processed": 9,
      "final_transcription": "In addition to that, I'm thinking that there might be actual value in  Potentially, I'm not saying this for a fact, but potentially having progressive  improvements on transcription meaning that we could have like a quick first snap at the transcription and  Then a behind-the-scenes process of improving the transcription with a more  Sophisticated model where you would do a diff and then kind of come up with a  Determination of whether or not the diff is improving or not which probably will right  But but that's kind of something that I've been thinking about",
      "chunk_boundary_artifacts": 8,
      "overall_quality_score": 0.7899999999999999,
      "processing_queue_transcription": "In addition to that, I'm thinking that there might be actual value in  Potentially, I'm not saying this for a fact, but potentially having progressive  improvements on transcription meaning that we could have like a quick first snap at the transcription and  Then a behind-the-scenes process of improving the transcription with a more  Sophisticated model where you would do a diff and then kind of come up with a  Determination of whether or not the diff is improving or not which probably will right  But but that's kind of something that I've been thinking about",
      "quality_vs_processing_queue": 1.0,
      "success": true,
      "error": null
    }
  ],
  "analysis": {
    "optimal_chunk_size": 500,
    "chunk_size_recommendations": [
      {
        "chunk_size_ms": 500,
        "avg_first_result_latency_ms": 500.0,
        "avg_quality_score": 0.7859999999999999,
        "use_case": "Ultra-responsive applications",
        "recommendation": "Recommended for most use cases"
      },
      {
        "chunk_size_ms": 1000,
        "avg_first_result_latency_ms": 1000.0,
        "avg_quality_score": 0.8379999999999999,
        "use_case": "Balanced dictation and note-taking",
        "recommendation": "Recommended for most use cases"
      },
      {
        "chunk_size_ms": 2000,
        "avg_first_result_latency_ms": 2000.0,
        "avg_quality_score": 0.8779999999999999,
        "use_case": "Quality-focused professional use",
        "recommendation": "Recommended for most use cases"
      },
      {
        "chunk_size_ms": 3000,
        "avg_first_result_latency_ms": 3000.0,
        "avg_quality_score": 0.89,
        "use_case": "Conservative high-quality transcription",
        "recommendation": "Consider for quality-critical scenarios"
      },
      {
        "chunk_size_ms": 5000,
        "avg_first_result_latency_ms": 5000.0,
        "avg_quality_score": 0.9099999999999999,
        "use_case": "Maximum quality applications",
        "recommendation": "Consider for quality-critical scenarios"
      }
    ],
    "quality_vs_latency_analysis": [
      {
        "chunk_size_ms": 500,
        "avg_latency_ms": 500.0,
        "avg_quality": 0.7859999999999999,
        "efficiency_score": 1.5719999999999998
      },
      {
        "chunk_size_ms": 1000,
        "avg_latency_ms": 1000.0,
        "avg_quality": 0.8379999999999999,
        "efficiency_score": 0.8379999999999999
      },
      {
        "chunk_size_ms": 2000,
        "avg_latency_ms": 2000.0,
        "avg_quality": 0.8779999999999999,
        "efficiency_score": 0.43899999999999995
      },
      {
        "chunk_size_ms": 3000,
        "avg_latency_ms": 3000.0,
        "avg_quality": 0.89,
        "efficiency_score": 0.2966666666666667
      },
      {
        "chunk_size_ms": 5000,
        "avg_latency_ms": 5000.0,
        "avg_quality": 0.9099999999999999,
        "efficiency_score": 0.182
      }
    ],
    "summary": "Analysis of 5 chunk sizes across 25 recordings. Optimal chunk size: 500ms for best quality-latency balance."
  }
}