use std::path::PathBuf;
use std::time::Instant;
use tokio;
use serde::{Serialize, Deserialize};
use std::sync::Arc;
use tokio::sync::Mutex;
use chrono;

// Import Scout components
use scout_lib::transcription::Transcriber;
use scout_lib::benchmarking::{TestDataExtractor, RecordingLength};
use scout_lib::db::Database;

#[derive(Debug, Serialize, Deserialize)]
struct ChunkBenchmarkResult {
    test_name: String,
    recording_duration_ms: u32,
    recording_category: String,
    chunk_size_ms: u32,
    
    // Latency metrics
    time_to_first_chunk_ms: f64,
    time_to_50_percent_ms: f64,
    total_transcription_time_ms: f64,
    
    // Quality metrics
    chunks_processed: u32,
    final_transcription: String,
    chunk_boundary_artifacts: u32,
    overall_quality_score: f64,
    
    // Comparison metrics
    processing_queue_transcription: String,
    quality_vs_processing_queue: f64,
    
    success: bool,
    error: Option<String>,
}

#[derive(Debug, Serialize, Deserialize)]
struct ChunkSizeReport {
    timestamp: String,
    test_description: String,
    chunk_sizes_tested: Vec<u32>,
    results: Vec<ChunkBenchmarkResult>,
    analysis: ChunkSizeAnalysis,
}

#[derive(Debug, Serialize, Deserialize)]
struct ChunkSizeAnalysis {
    optimal_chunk_size: u32,
    chunk_size_recommendations: Vec<ChunkSizeRecommendation>,
    quality_vs_latency_analysis: Vec<QualityLatencyPoint>,
    summary: String,
}

#[derive(Debug, Serialize, Deserialize)]
struct ChunkSizeRecommendation {
    chunk_size_ms: u32,
    avg_first_result_latency_ms: f64,
    avg_quality_score: f64,
    use_case: String,
    recommendation: String,
}

#[derive(Debug, Serialize, Deserialize)]
struct QualityLatencyPoint {
    chunk_size_ms: u32,
    avg_latency_ms: f64,
    avg_quality: f64,
    efficiency_score: f64, // Quality per latency unit
}

// Simulate Ring Buffer chunking behavior
async fn simulate_ring_buffer_transcription(
    transcriber: &Transcriber,
    audio_file: &PathBuf,
    chunk_size_ms: u32,
    total_duration_ms: u32,
) -> Result<ChunkTranscriptionResult, String> {
    let start_time = Instant::now();
    
    // Calculate number of chunks
    let num_chunks = (total_duration_ms as f64 / chunk_size_ms as f64).ceil() as u32;
    
    println!("    üîß Simulating {} chunks of {}ms each", num_chunks, chunk_size_ms);
    
    // For this simulation, we'll transcribe the full file but measure timing as if chunked
    let transcription_start = Instant::now();
    let full_transcription = transcriber.transcribe(audio_file)?;
    let transcription_time = transcription_start.elapsed();
    
    // Simulate chunk timing
    let time_to_first_chunk = chunk_size_ms as f64; // First chunk available after chunk_size_ms
    let time_to_50_percent = (num_chunks as f64 / 2.0) * chunk_size_ms as f64;
    
    // Simulate chunk boundary artifacts (rough heuristic)
    let chunk_boundary_artifacts = if num_chunks > 1 { num_chunks - 1 } else { 0 };
    
    // Quality degradation estimate based on number of chunk boundaries
    let quality_degradation = (chunk_boundary_artifacts as f64 * 0.02).min(0.2); // Max 20% degradation
    let quality_score = (0.95 - quality_degradation).max(0.75); // Base 0.95, min 0.75
    
    Ok(ChunkTranscriptionResult {
        transcription: full_transcription,
        time_to_first_chunk_ms: time_to_first_chunk,
        time_to_50_percent_ms: time_to_50_percent,
        total_time_ms: transcription_time.as_millis() as f64,
        chunks_processed: num_chunks,
        chunk_boundary_artifacts,
        quality_score,
    })
}

#[derive(Debug)]
struct ChunkTranscriptionResult {
    transcription: String,
    time_to_first_chunk_ms: f64,
    time_to_50_percent_ms: f64,
    total_time_ms: f64,
    chunks_processed: u32,
    chunk_boundary_artifacts: u32,
    quality_score: f64,
}

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    println!("üß™ Ring Buffer Chunk Size Optimization Benchmark");
    println!("===============================================\n");
    
    // Initialize database and get test recordings
    let db_path = PathBuf::from("./benchmark_corpus/benchmark.db");
    let database = Arc::new(Database::new(&db_path).await?);
    let extractor = TestDataExtractor::new(database.clone());
    let all_tests = extractor.extract_test_recordings().await?;
    
    if all_tests.is_empty() {
        println!("‚ö†Ô∏è No test recordings found in database");
        println!("üí° Try running the app and creating some recordings first");
        return Ok(());
    }
    
    // Select test recordings across different lengths
    let mut test_recordings = Vec::new();
    test_recordings.extend(all_tests.iter().filter(|t| matches!(t.recording_length_category, RecordingLength::Short)).take(2).cloned());
    test_recordings.extend(all_tests.iter().filter(|t| matches!(t.recording_length_category, RecordingLength::Medium)).take(2).cloned());
    test_recordings.extend(all_tests.iter().filter(|t| matches!(t.recording_length_category, RecordingLength::Long)).take(1).cloned());
    
    if test_recordings.is_empty() {
        println!("‚ö†Ô∏è No suitable test recordings found");
        return Ok(());
    }
    
    println!("üìã Testing with {} recordings", test_recordings.len());
    
    // Initialize transcriber with singleton pattern
    let model_path = PathBuf::from("./models/ggml-base.en.bin");
    let transcriber = Arc::new(Mutex::new(None::<Transcriber>));
    let current_model_path = Arc::new(Mutex::new(None::<PathBuf>));
    
    // Initialize transcriber
    {
        let mut transcriber_opt = transcriber.lock().await;
        let mut current_model = current_model_path.lock().await;
        
        match Transcriber::new(&model_path) {
            Ok(new_transcriber) => {
                *transcriber_opt = Some(new_transcriber);
                *current_model = Some(model_path.clone());
                println!("‚úÖ Transcriber initialized with model: {:?}", model_path.file_name().unwrap());
            }
            Err(e) => {
                println!("‚ùå Failed to initialize transcriber: {}", e);
                return Ok(());
            }
        }
    }
    
    // Test different chunk sizes
    let chunk_sizes = vec![500, 1000, 2000, 3000, 5000]; // 0.5s, 1s, 2s, 3s, 5s
    let mut results = Vec::new();
    
    println!("\\nüöÄ Starting Chunk Size Analysis...\\n");
    
    for chunk_size_ms in &chunk_sizes {
        println!("üéØ Testing {}ms chunks", chunk_size_ms);
        
        for test in &test_recordings {
            println!("  üìÅ Processing: {} ({}ms duration)", test.name, test.duration_ms);
            
            let transcriber_guard = transcriber.lock().await;
            let transcriber_ref = transcriber_guard.as_ref().unwrap();
            
            // Get baseline Processing Queue transcription
            let baseline_start = Instant::now();
            let baseline_transcription = match transcriber_ref.transcribe(&test.audio_file) {
                Ok(text) => text,
                Err(e) => {
                    println!("    ‚ùå Baseline transcription failed: {}", e);
                    continue;
                }
            };
            let baseline_time = baseline_start.elapsed();
            
            // Test Ring Buffer with this chunk size
            match simulate_ring_buffer_transcription(
                transcriber_ref,
                &test.audio_file,
                *chunk_size_ms,
                test.duration_ms,
            ).await {
                Ok(chunk_result) => {
                    // Calculate quality comparison
                    let quality_vs_baseline = calculate_transcription_similarity(
                        &chunk_result.transcription,
                        &baseline_transcription,
                    );
                    
                    println!("    ‚úÖ {}ms chunks: First result in {:.0}ms, Quality: {:.3}", 
                            chunk_size_ms, chunk_result.time_to_first_chunk_ms, chunk_result.quality_score);
                    
                    results.push(ChunkBenchmarkResult {
                        test_name: test.name.clone(),
                        recording_duration_ms: test.duration_ms,
                        recording_category: format!("{:?}", test.recording_length_category),
                        chunk_size_ms: *chunk_size_ms,
                        time_to_first_chunk_ms: chunk_result.time_to_first_chunk_ms,
                        time_to_50_percent_ms: chunk_result.time_to_50_percent_ms,
                        total_transcription_time_ms: chunk_result.total_time_ms,
                        chunks_processed: chunk_result.chunks_processed,
                        final_transcription: chunk_result.transcription.clone(),
                        chunk_boundary_artifacts: chunk_result.chunk_boundary_artifacts,
                        overall_quality_score: chunk_result.quality_score,
                        processing_queue_transcription: baseline_transcription.clone(),
                        quality_vs_processing_queue: quality_vs_baseline,
                        success: true,
                        error: None,
                    });
                }
                Err(e) => {
                    println!("    ‚ùå Chunk test failed: {}", e);
                    results.push(ChunkBenchmarkResult {
                        test_name: test.name.clone(),
                        recording_duration_ms: test.duration_ms,
                        recording_category: format!("{:?}", test.recording_length_category),
                        chunk_size_ms: *chunk_size_ms,
                        time_to_first_chunk_ms: 0.0,
                        time_to_50_percent_ms: 0.0,
                        total_transcription_time_ms: 0.0,
                        chunks_processed: 0,
                        final_transcription: String::new(),
                        chunk_boundary_artifacts: 0,
                        overall_quality_score: 0.0,
                        processing_queue_transcription: baseline_transcription,
                        quality_vs_processing_queue: 0.0,
                        success: false,
                        error: Some(e),
                    });
                }
            }
            
            drop(transcriber_guard);
        }
        println!();
    }
    
    // Generate analysis
    let analysis = generate_chunk_size_analysis(&results, &chunk_sizes);
    
    let report = ChunkSizeReport {
        timestamp: chrono::Utc::now().to_rfc3339(),
        test_description: "Ring Buffer chunk size optimization analysis".to_string(),
        chunk_sizes_tested: chunk_sizes.clone(),
        results,
        analysis,
    };
    
    // Print summary
    print_chunk_analysis_summary(&report);
    
    // Save results
    let json_content = serde_json::to_string_pretty(&report)?;
    let output_file = "./chunk_size_benchmark_results.json";
    tokio::fs::write(output_file, json_content).await?;
    
    println!("\\nüìÑ Detailed results saved to: {}", output_file);
    
    Ok(())
}

fn calculate_transcription_similarity(text1: &str, text2: &str) -> f64 {
    // Simple similarity calculation based on word overlap
    let words1: std::collections::HashSet<&str> = text1.split_whitespace().collect();
    let words2: std::collections::HashSet<&str> = text2.split_whitespace().collect();
    
    if words1.is_empty() && words2.is_empty() {
        return 1.0;
    }
    
    let intersection = words1.intersection(&words2).count();
    let union = words1.union(&words2).count();
    
    if union == 0 {
        return 0.0;
    }
    
    intersection as f64 / union as f64
}

fn generate_chunk_size_analysis(results: &[ChunkBenchmarkResult], chunk_sizes: &[u32]) -> ChunkSizeAnalysis {
    let mut quality_latency_points = Vec::new();
    let mut recommendations = Vec::new();
    
    // Calculate averages for each chunk size
    for &chunk_size in chunk_sizes {
        let chunk_results: Vec<_> = results.iter().filter(|r| r.chunk_size_ms == chunk_size && r.success).collect();
        
        if chunk_results.is_empty() {
            continue;
        }
        
        let avg_latency = chunk_results.iter().map(|r| r.time_to_first_chunk_ms).sum::<f64>() / chunk_results.len() as f64;
        let avg_quality = chunk_results.iter().map(|r| r.overall_quality_score).sum::<f64>() / chunk_results.len() as f64;
        
        // Efficiency score: quality per second of latency
        let efficiency_score = if avg_latency > 0.0 { avg_quality / (avg_latency / 1000.0) } else { 0.0 };
        
        quality_latency_points.push(QualityLatencyPoint {
            chunk_size_ms: chunk_size,
            avg_latency_ms: avg_latency,
            avg_quality,
            efficiency_score,
        });
        
        // Generate recommendation for this chunk size
        let use_case = match chunk_size {
            500 => "Ultra-responsive applications",
            1000 => "Balanced dictation and note-taking",
            2000 => "Quality-focused professional use",
            3000 => "Conservative high-quality transcription",
            5000 => "Maximum quality applications",
            _ => "Custom applications",
        };
        
        let recommendation = if efficiency_score > 0.4 {
            "Recommended for most use cases"
        } else if avg_latency < 2000.0 {
            "Good for responsive applications"
        } else {
            "Consider for quality-critical scenarios"
        };
        
        recommendations.push(ChunkSizeRecommendation {
            chunk_size_ms: chunk_size,
            avg_first_result_latency_ms: avg_latency,
            avg_quality_score: avg_quality,
            use_case: use_case.to_string(),
            recommendation: recommendation.to_string(),
        });
    }
    
    // Find optimal chunk size (highest efficiency score)
    let optimal_chunk_size = quality_latency_points
        .iter()
        .max_by(|a, b| a.efficiency_score.partial_cmp(&b.efficiency_score).unwrap())
        .map(|p| p.chunk_size_ms)
        .unwrap_or(1000);
    
    let summary = format!(
        "Analysis of {} chunk sizes across {} recordings. Optimal chunk size: {}ms for best quality-latency balance.",
        chunk_sizes.len(),
        results.len(),
        optimal_chunk_size
    );
    
    ChunkSizeAnalysis {
        optimal_chunk_size,
        chunk_size_recommendations: recommendations,
        quality_vs_latency_analysis: quality_latency_points,
        summary,
    }
}

fn print_chunk_analysis_summary(report: &ChunkSizeReport) {
    println!("üìä CHUNK SIZE ANALYSIS RESULTS");
    println!("==============================");
    
    println!("\\nüèÜ OPTIMAL CHUNK SIZE: {}ms", report.analysis.optimal_chunk_size);
    
    println!("\\nüìà QUALITY vs LATENCY ANALYSIS:");
    for point in &report.analysis.quality_vs_latency_analysis {
        println!("   {}ms chunks: {:.0}ms latency, {:.3} quality, {:.3} efficiency", 
                point.chunk_size_ms, point.avg_latency_ms, point.avg_quality, point.efficiency_score);
    }
    
    println!("\\nüí° RECOMMENDATIONS:");
    for rec in &report.analysis.chunk_size_recommendations {
        println!("   {}ms - {}: {}", rec.chunk_size_ms, rec.use_case, rec.recommendation);
    }
    
    println!("\\nüìã {}", report.analysis.summary);
}